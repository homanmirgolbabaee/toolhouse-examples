{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Research Service Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Overview\n",
        "Build a research assistant that can search the web, analyze content, and provide comprehensive reports using Toolhouse.ai's pre-built tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfSxUmseQhHC",
        "outputId": "3e9ae29b-3967-4362-da13-bfbc198f1596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting toolhouse\n",
            "  Downloading toolhouse-1.4.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting anthropic (from toolhouse)\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting groq (from toolhouse)\n",
            "  Downloading groq-0.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting http-exceptions (from toolhouse)\n",
            "  Downloading http_exceptions-0.2.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from toolhouse) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->toolhouse) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->toolhouse) (2.4.0)\n",
            "Downloading toolhouse-1.4.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.24.0-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading http_exceptions-0.2.10-py3-none-any.whl (8.8 kB)\n",
            "Installing collected packages: python-dotenv, http-exceptions, groq, anthropic, toolhouse\n",
            "Successfully installed anthropic-0.51.0 groq-0.24.0 http-exceptions-0.2.10 python-dotenv-1.1.0 toolhouse-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install toolhouse openai python-dotenv pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfDsbXspQjwD",
        "outputId": "59eaa38f-6ab3-4457-ef29-506a948a5b39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import dependencies\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from toolhouse import Toolhouse, Provider\n",
        "import pandas as pd\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckYK8GxsQjt3"
      },
      "outputs": [],
      "source": [
        "# Set up API keys\n",
        "TOOLHOUSE_API_KEY = \"toolhouse_api_key\"\n",
        "OPENAI_API_KEY = \"openai_api_key\"\n",
        "\n",
        "# Initialize clients\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "th = Toolhouse(api_key=TOOLHOUSE_API_KEY, provider=Provider.OPENAI)\n",
        "\n",
        "# Model configuration\n",
        "MODEL = 'gpt-4o'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JuxPwII-Qjry"
      },
      "outputs": [],
      "source": [
        "def research_topic(topic, depth=\"medium\", sources_count=3):\n",
        "    \"\"\"\n",
        "    Research a topic using Toolhouse tools\n",
        "\n",
        "    Args:\n",
        "        topic: The research topic\n",
        "        depth: \"quick\", \"medium\", or \"deep\"\n",
        "        sources_count: Number of sources to gather\n",
        "    \"\"\"\n",
        "\n",
        "    # Adjust system prompt based on depth\n",
        "    depth_instructions = {\n",
        "        \"quick\": \"Provide a concise summary with key points\",\n",
        "        \"medium\": \"Provide a comprehensive overview with analysis\",\n",
        "        \"deep\": \"Conduct thorough research with detailed analysis and multiple perspectives\"\n",
        "    }\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "    You are a professional research assistant. Your task is to research the topic: \"{topic}\"\n",
        "\n",
        "    Research Requirements:\n",
        "    - Search for {sources_count} different sources\n",
        "    - {depth_instructions[depth]}\n",
        "    - Verify information from multiple sources\n",
        "    - Include relevant data, statistics, and expert opinions\n",
        "    - Cite sources appropriately\n",
        "\n",
        "    Use available tools to:\n",
        "    1. Search for current information\n",
        "    2. Access relevant websites and documents\n",
        "    3. Gather diverse perspectives\n",
        "\n",
        "    Format your response as a structured research report.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Please research: {topic}\"}\n",
        "    ]\n",
        "\n",
        "    # Get response with tools\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=th.get_tools(),\n",
        "        max_tokens=2000\n",
        "    )\n",
        "\n",
        "    # Process tools and continue\n",
        "    messages = th.run_tools(response, messages)\n",
        "\n",
        "    # Get final research report\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        max_tokens=2000\n",
        "    )\n",
        "\n",
        "    return final_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afh7e5ZVQjpp",
        "outputId": "ea45042a-9369-4f28-8007-5828debe75b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The impact of AI on healthcare in 2024 is substantial, with numerous applications and innovations already transforming the industry. Here's a summary of key points gathered from the searches:\n",
            "\n",
            "1. **Diagnostic Accuracy**: AI enhances diagnostic precision, particularly in analyzing medical images for diseases such as cancer and heart disease. In 2024, AI's capabilities are further advanced, recognizing patterns invisible to the human eye, thus aiding in early and accurate disease diagnosis.\n",
            "\n",
            "2. **Personalized Medicine**: AI facilitates the creation of individualized treatment plans by processing extensive data, including genetic information and lifestyle factors. This personalization improves treatment efficacy while minimizing side effects.\n",
            "\n",
            "3. **Administrative Efficiency**: AI automates routine administrative tasks, thereby reducing healthcare professionals' workload and allowing them to focus more on patient care. Applications include scheduling, billing, and managing patient information.\n",
            "\n",
            "4. **Drug Discovery and Development**: AI accelerates the drug discovery process by predicting chemical and biological interactions, significantly reducing the time and cost involved in developing new drugs.\n",
            "\n",
            "5. **Patient Engagement and Monitoring**: AI-powered virtual assistants and health apps enhance patient engagement by providing real-time health insights and reminders. Wearable AI devices monitor vital signs and alert medical professionals to potential issues, enhancing remote patient care.\n",
            "\n",
            "6. **Mental Health**: AI tools assist in early detection and intervention of mental health conditions by analyzing speech patterns and other data sources. These tools connect individuals to appropriate resources and support.\n",
            "\n",
            "7. **Telehealth and Remote Services**: The integration of AI with telehealth services improves accessibility and quality of remote healthcare, offering diagnostic tools and virtual assistance during consultations.\n",
            "\n",
            "8. **Projected Growth and Challenges**: The healthcare AI market is expected to expand significantly, driven by technological advancements and the increasing availability of large datasets. However, challenges such as data privacy, standardization, and potential bias remain critical areas of concern.\n",
            "\n",
            "9. **Future Prospects**: Over the next decade, AI is expected to be further integrated into healthcare, transforming various domains like genomics and life sciences. It promises improved diagnostic accuracy, personalized treatments, and cost savings, but requires careful navigation of ethical and privacy challenges.\n",
            "\n",
            "For a deeper exploration into these topics, you may refer to the specific articles and reviews available [here](https://www.linkedin.com/pulse/healthcare-2024-reshaped-ai-innovations-effects-fxisai-ed88f) and [here](https://careful.online/future-healthcare-ai-2024/).\n"
          ]
        }
      ],
      "source": [
        "research_report = research_topic(\n",
        "    \"Impact of AI on healthcare in 2024\",\n",
        "    depth=\"medium\",\n",
        "    sources_count=5\n",
        ")\n",
        "print(research_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cj79lhScQjna"
      },
      "outputs": [],
      "source": [
        "class ResearchPipeline:\n",
        "    def __init__(self, client, toolhouse):\n",
        "        self.client = client\n",
        "        self.th = toolhouse\n",
        "        self.research_data = {}\n",
        "\n",
        "    def initial_search(self, topic):\n",
        "        \"\"\"Stage 1: Initial broad search\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"\n",
        "            Conduct an initial search on \"{topic}\".\n",
        "            Find 3-5 diverse sources and provide a brief overview of each.\n",
        "            Return the information in JSON format with source URLs and summaries.\n",
        "            \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Search for information about: {topic}\"}\n",
        "        ]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=self.th.get_tools()\n",
        "        )\n",
        "\n",
        "        messages = self.th.run_tools(response, messages)\n",
        "\n",
        "        final_response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        return final_response.choices[0].message.content\n",
        "\n",
        "    def deep_dive_analysis(self, topic, initial_findings):\n",
        "        \"\"\"Stage 2: Deep dive into specific aspects\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"\n",
        "            Based on the initial findings, conduct a deeper analysis of \"{topic}\".\n",
        "\n",
        "            Initial findings: {initial_findings}\n",
        "\n",
        "            Focus on:\n",
        "            1. Recent developments and trends\n",
        "            2. Expert opinions and analysis\n",
        "            3. Statistical data and case studies\n",
        "            4. Future implications\n",
        "\n",
        "            Scrape relevant pages for detailed information.\n",
        "            \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": \"Provide detailed analysis based on the initial findings\"}\n",
        "        ]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=self.th.get_tools()\n",
        "        )\n",
        "\n",
        "        messages = self.th.run_tools(response, messages)\n",
        "\n",
        "        final_response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            max_tokens=1500\n",
        "        )\n",
        "\n",
        "        return final_response.choices[0].message.content\n",
        "\n",
        "    def synthesize_report(self, topic, initial_findings, deep_analysis):\n",
        "        \"\"\"Stage 3: Synthesize into final report\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"\n",
        "            Create a comprehensive research report on \"{topic}\" by synthesizing\n",
        "            the gathered information.\n",
        "\n",
        "            Structure the report with:\n",
        "            1. Executive Summary\n",
        "            2. Current State Analysis\n",
        "            3. Key Findings\n",
        "            4. Trends and Patterns\n",
        "            5. Future Outlook\n",
        "            6. Recommendations\n",
        "            7. Sources and References\n",
        "\n",
        "            Make it professional and well-organized.\n",
        "            \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"\n",
        "            Initial findings: {initial_findings}\n",
        "\n",
        "            Deep analysis: {deep_analysis}\n",
        "\n",
        "            Please synthesize this into a final research report.\n",
        "            \"\"\"}\n",
        "        ]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            max_tokens=2000\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def run_full_research(self, topic):\n",
        "        \"\"\"Run the complete research pipeline\"\"\"\n",
        "        print(f\"🔍 Starting research on: {topic}\")\n",
        "\n",
        "        # Stage 1: Initial search\n",
        "        print(\"📋 Stage 1: Initial search...\")\n",
        "        initial_findings = self.initial_search(topic)\n",
        "\n",
        "        # Stage 2: Deep dive\n",
        "        print(\"🔬 Stage 2: Deep dive analysis...\")\n",
        "        deep_analysis = self.deep_dive_analysis(topic, initial_findings)\n",
        "\n",
        "        # Stage 3: Synthesize\n",
        "        print(\"📊 Stage 3: Synthesizing report...\")\n",
        "        final_report = self.synthesize_report(topic, initial_findings, deep_analysis)\n",
        "\n",
        "        print(\"✅ Research complete!\")\n",
        "        return final_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc86f7jGQjlP",
        "outputId": "089ac8c2-6551-49fb-ed8c-fa461258cce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Starting research on: Quantum computing breakthroughs in 2024\n",
            "📋 Stage 1: Initial search...\n",
            "🔬 Stage 2: Deep dive analysis...\n",
            "📊 Stage 3: Synthesizing report...\n",
            "✅ Research complete!\n",
            "# Quantum Computing Breakthroughs in 2024: A Comprehensive Research Report\n",
            "\n",
            "## 1. Executive Summary\n",
            "\n",
            "Quantum computing, once relegated to theoretical research and small-scale demonstrations, has made substantial strides forward in 2024. Notable developments include the advancement of super-pure silicon chips and Google’s revolutionary Willow quantum computing chip. These innovations have significantly enhanced quantum coherence times and error rate reduction, propelling quantum computing closer to practical applications across diverse sectors such as artificial intelligence, secure communication, and drug design. This report analyzes these breakthroughs, examines their implications on the current state of quantum computing, and assesses future directions.\n",
            "\n",
            "## 2. Current State Analysis\n",
            "\n",
            "As of 2024, the primary challenges in quantum computing involve coherence time - the duration a quantum bit (qubit) maintains its informational state - and error rates during computation. Qubits, especially in solid-state quantum computers, are susceptible to environmental \"noise\" that can lead to errors in calculations. Solutions have involved various approaches towards stabilization and error correction, with companies and academic institutions worldwide competing to realize scalable, reliable quantum systems.\n",
            "\n",
            "## 3. Key Findings\n",
            "\n",
            "1. **Super-Pure Silicon Chip Development**: \n",
            "    - Led by researchers from the Universities of Melbourne and Manchester, this development utilizes ultra-pure silicon, minimizing silicon-29 impurities known for causing coherence difficulties. By reducing these impurities through ion implantation, the technique significantly extends quantum coherence, leading to enhanced calculation accuracy.\n",
            "\n",
            "2. **Google's Quantum Computing Chip - 'Willow'**:\n",
            "    - Google's Willow chip shows a remarkable leap in computational power and error correction. Achieving calculations in minutes that would take classical supercomputers billions of years, the chip achieves exponential error reduction as additional qubits are integrated. This result suggests scalable quantum computers applicable soon for concrete, real-world problem-solving.\n",
            "\n",
            "## 4. Trends and Patterns\n",
            "\n",
            "- The integration of more refined materials like ultra-pure silicon indicates a continued shift towards material science solutions for quantum computing challenges.\n",
            "- Tech giants like Google are setting precedence in achieving computational capabilities previously unimaginable, indicating a potential future market dominated by similar advancements.\n",
            "- There’s a visible pattern of convergence between institutional research and corporate innovation, each supporting large leaps forward in this promising field.\n",
            "\n",
            "## 5. Future Outlook\n",
            "\n",
            "Looking forward, these breakthroughs suggest a near-term realization of practical quantum computing solutions. Immediate applications are likely across high-complexity and data-intensive sectors, including pharmaceuticals, where quantum supremacy could revolutionize drug discovery and design procedures. As techniques for enhanced coherence and error correction continue to mature, businesses and science communities should prepare for transformative capabilities brought on by quantum technologies.\n",
            "\n",
            "## 6. Recommendations\n",
            "\n",
            "- **Investment in Material Science**: Support further research in advanced materials for quantum computing, particularly those that enhance coherence and reduce errors.\n",
            "- **Cross-disciplinary Collaboration**: Encourage collaborative projects between technology companies and research universities to drive innovation.\n",
            "- **Developing Quantum Software Ecosystems**: With emerging quantum hardware capabilities, developing robust quantum software frameworks should be prioritized.\n",
            "- **Training and Workforce Development**: Establish training programs to develop quantum technology literacy and skills across various industries.\n",
            "\n",
            "## 7. Sources and References\n",
            "\n",
            "- Science Daily. “Researchers from the Universities of Melbourne and Manchester Develop Super-Pure Silicon Chips.” Available at: [Science Daily](https://www.sciencedaily.com/releases/2024/05/240507150004.htm)\n",
            "- Tech Xplore. “Google Unveils Quantum Computing Chip ‘Willow’ with Unprecedented Capabilities.” Available at: [Tech Xplore](https://techxplore.com/news/2024-12-google-quantum-chip-breakthrough.html)\n",
            "- Google Blog. “An Inside Look at Google's Willow Quantum Chip Breakthrough.” Available at: [Google Blog](https://blog.google/technology/research/google-willow-quantum-chip/)\n",
            "\n",
            "In compiling this report, significant emphasis was placed on highlighting developments from prominent industry leaders and respected academic institutions to provide a comprehensive overview of the quantum computing landscape as it stands today and its implications for the future.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "pipeline = ResearchPipeline(client, th)\n",
        "report = pipeline.run_full_research(\"Quantum computing breakthroughs in 2024\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tNO4YgkPQji0"
      },
      "outputs": [],
      "source": [
        "def compare_topics(topic_a, topic_b, comparison_criteria=None):\n",
        "    \"\"\"Compare two topics side by side\"\"\"\n",
        "\n",
        "    if not comparison_criteria:\n",
        "        comparison_criteria = [\n",
        "            \"Market size and growth\",\n",
        "            \"Key players and competitors\",\n",
        "            \"Technological advantages\",\n",
        "            \"Challenges and limitations\",\n",
        "            \"Future prospects\"\n",
        "        ]\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "    Conduct a comparative analysis between \"{topic_a}\" and \"{topic_b}\".\n",
        "\n",
        "    Compare them across these criteria:\n",
        "    {chr(10).join(f\"- {criteria}\" for criteria in comparison_criteria)}\n",
        "\n",
        "    Research both topics thoroughly and provide:\n",
        "    1. Summary of each topic\n",
        "    2. Side-by-side comparison table\n",
        "    3. Key differences and similarities\n",
        "    4. Advantages and disadvantages of each\n",
        "    5. Conclusions and recommendations\n",
        "\n",
        "    Use web search and content analysis tools to gather current information.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Compare {topic_a} vs {topic_b}\"}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=th.get_tools(),\n",
        "        max_tokens=2500\n",
        "    )\n",
        "\n",
        "    messages = th.run_tools(response, messages)\n",
        "\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        max_tokens=2500\n",
        "    )\n",
        "\n",
        "    return final_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWfsPb0sQjgk",
        "outputId": "83aa6d03-8ffb-4219-f8cf-cd2d051b6d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the gathered information, here is an overview of electric vehicles (EVs) and hydrogen fuel cell vehicles (HFCVs) concerning their environmental impacts, infrastructure, costs, and performance:\n",
            "\n",
            "**Electric Vehicles (EVs):**\n",
            "1. **Environmental Impact:**\n",
            "   - EVs generally have lower lifecycle greenhouse gas (GHG) emissions compared to internal combustion engine vehicles (ICEVs). Most emissions in EVs are concentrated in the battery production and electricity generation stages.\n",
            "   - The type of electricity used for charging significantly influences the environmental benefits. Charging from renewable sources maximizes GHG reductions.\n",
            "\n",
            "2. **Infrastructure:**\n",
            "   - EVs require an extensive charging network. Infrastructure development is advanced in several regions but still lacks in rural and underserved areas.\n",
            "   - Investments in fast-charging networks and battery technology advancements are crucial to addressing range anxiety and improving adoption rates.\n",
            "\n",
            "3. **Costs:**\n",
            "   - The costs of EVs are declining but they remain higher than ICEVs primarily due to battery prices.\n",
            "   - Economic incentives and subsidies can help offset initial purchase costs.\n",
            "\n",
            "4. **Performance:**\n",
            "   - EVs offer high energy efficiency with electric motors but are affected by temperature, which can reduce their range.\n",
            "   - The driving range is increasing with advancements in battery technology.\n",
            "\n",
            "**Hydrogen Fuel Cell Vehicles (HFCVs):**\n",
            "1. **Environmental Impact:**\n",
            "   - HFCVs emit only water vapor, making them highly attractive for reducing pollution and GHGs if hydrogen is produced from renewable sources.\n",
            "   - The production of hydrogen can generate emissions unless green hydrogen production methods, like electrolysis from renewable energy, are used.\n",
            "\n",
            "2. **Infrastructure:**\n",
            "   - Hydrogen refueling infrastructure is limited in scope and development, with concentrated networks especially in regions like California.\n",
            "   - Significant investment is needed to expand infrastructure for wider adoption.\n",
            "\n",
            "3. **Costs:**\n",
            "   - HFCVs are generally more expensive due to high costs in fuel cell technology and hydrogen production, which are not yet as economically competitive as battery-electric technologies.\n",
            "   - As technology improves and economies of scale are realized, costs are expected to come down.\n",
            "\n",
            "4. **Performance:**\n",
            "   - HFCVs typically offer a longer driving range similar to conventional vehicles and refuel quickly (3-5 minutes), addressing the range anxiety issue prevalent with battery EVs.\n",
            "   - The energy efficiency of HFCVs needs improvement compared to EVs, due to energy losses in hydrogen production and fuel cell systems.\n",
            "\n",
            "**Conclusion:**\n",
            "Both EVs and HFCVs hold potential for sustainable transportation with unique advantages and challenges. EVs currently have a more established market presence due to mature technology and infrastructure. HFCVs could play a crucial role in heavy transportation sectors and geographies where rapid refueling is advantageous, should challenges related to cost, infrastructure, and hydrogen production be addressed effectively. Sustainable transitions will involve integrated strategies across technologies, leveraging both battery-electric and hydrogen solutions for different applications.\n"
          ]
        }
      ],
      "source": [
        "# Example comparison\n",
        "comparison = compare_topics(\n",
        "    \"Electric vehicles\",\n",
        "    \"Hydrogen fuel cell vehicles\",\n",
        "    [\"Environmental impact\", \"Infrastructure requirements\", \"Cost factors\", \"Performance metrics\"]\n",
        ")\n",
        "print(comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ml5eBM43Q1OS"
      },
      "outputs": [],
      "source": [
        "class PersistentResearchAssistant:\n",
        "    def __init__(self, client, toolhouse):\n",
        "        self.client = client\n",
        "        self.th = toolhouse\n",
        "        self.research_memory = []\n",
        "        self.session_id = None\n",
        "\n",
        "    def start_research_session(self, session_name):\n",
        "        \"\"\"Start a new research session\"\"\"\n",
        "        self.session_id = session_name\n",
        "        self.research_memory = []\n",
        "        print(f\"Started research session: {session_name}\")\n",
        "\n",
        "    def add_research_context(self, topic, findings):\n",
        "        \"\"\"Add research to memory\"\"\"\n",
        "        self.research_memory.append({\n",
        "            \"topic\": topic,\n",
        "            \"findings\": findings,\n",
        "            \"timestamp\": th.get_tools()  # Assuming current_time tool\n",
        "        })\n",
        "\n",
        "    def research_with_context(self, topic):\n",
        "        \"\"\"Research with awareness of previous research\"\"\"\n",
        "\n",
        "        # Build context from previous research\n",
        "        context = \"\"\n",
        "        if self.research_memory:\n",
        "            context = \"Previous research in this session:\\n\"\n",
        "            for item in self.research_memory[-3:]:  # Last 3 items\n",
        "                context += f\"- {item['topic']}: {item['findings'][:200]}...\\n\"\n",
        "\n",
        "        system_prompt = f\"\"\"\n",
        "        You are continuing a research session on related topics.\n",
        "\n",
        "        {context}\n",
        "\n",
        "        Current research topic: \"{topic}\"\n",
        "\n",
        "        Consider connections to previous research and build upon existing findings.\n",
        "        Use tools to gather new information while referencing relevant previous research.\n",
        "        \"\"\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"Research: {topic}\"}\n",
        "        ]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=self.th.get_tools()\n",
        "        )\n",
        "\n",
        "        messages = self.th.run_tools(response, messages)\n",
        "\n",
        "        final_response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            max_tokens=1500\n",
        "        )\n",
        "\n",
        "        findings = final_response.choices[0].message.content\n",
        "        self.add_research_context(topic, findings)\n",
        "\n",
        "        return findings\n",
        "\n",
        "    def generate_session_summary(self):\n",
        "        \"\"\"Generate summary of entire research session\"\"\"\n",
        "        if not self.research_memory:\n",
        "            return \"No research conducted in this session.\"\n",
        "\n",
        "        topics = [item['topic'] for item in self.research_memory]\n",
        "\n",
        "        system_prompt = f\"\"\"\n",
        "        Create a comprehensive summary of the research session: {self.session_id}\n",
        "\n",
        "        Topics researched: {', '.join(topics)}\n",
        "\n",
        "        Identify:\n",
        "        1. Common themes across all research\n",
        "        2. Key insights and patterns\n",
        "        3. Contradictions or gaps in findings\n",
        "        4. Recommended follow-up research\n",
        "        5. Executive summary\n",
        "\n",
        "        Create a cohesive narrative that connects all the research.\n",
        "        \"\"\"\n",
        "\n",
        "        # Combine all findings\n",
        "        all_findings = \"\\n\\n\".join([\n",
        "            f\"Topic: {item['topic']}\\nFindings: {item['findings']}\"\n",
        "            for item in self.research_memory\n",
        "        ])\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"Research findings to summarize:\\n\\n{all_findings}\"}\n",
        "        ]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            max_tokens=2000\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-4o65NBQ1MN",
        "outputId": "a8e86d35-0620-4cfb-dc35-8a12a8193bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started research session: AI Technology Review\n",
            "\n",
            "🔍 Researching: Large Language Models in 2024\n",
            "The field of Large Language Models (LLMs) has seen significant advancements and innovations in 2024, with a strong focus on enhancing efficiency, multimodal capabilities, specialized models, and collaborative open-source initiatives. Key developments include:\n",
            "\n",
            "1. **Enhanced Reasoning Abilities**: Mo...\n",
            "\n",
            "\n",
            "🔍 Researching: AI Ethics and Regulation\n",
            "In 2024, significant developments are emerging in the realm of AI ethics and regulation. Here are key insights:\n",
            "\n",
            "1. **EU AI Regulations**: The European Parliament's \"Artificial Intelligence Act\" provides harmonized rules on AI across the EU, although initially proposed ethical principles were omitte...\n",
            "\n",
            "\n",
            "🔍 Researching: AI in Enterprise Applications\n",
            "Artificial Intelligence (AI) is poised to significantly transform enterprise applications in 2024 and beyond. Here are some major trends and predictions:\n",
            "\n",
            "1. **AI-Driven Decision Making**: AI will be instrumental in enhancing decision-making processes within enterprises. By providing real-time analy...\n",
            "\n",
            "📋 Session Summary:\n",
            "**Executive Summary:**\n",
            "\n",
            "In 2024, the advancements in AI technologies, particularly in Large Language Models (LLMs), AI ethics and regulation, and their applications in enterprise, have marked significant transformation across various sectors. The central themes include enhanced capabilities, cross-sector applications, ethical considerations, and regulatory landscapes, which are pivotal in navigating the complex AI milieu. Key insights reflect a concerted drive towards sophistication in AI systems, greater multimodality, and proactive measures in governance to align AI growth with ethical and societal values. Despite these advancements, certain contradictions and gaps emerge, particularly in the harmonization of global regulations and the balance between innovation and ethical adherence. Future research should explore the impact of AI on societal structures and global collaboration in regulatory practices. These developments emphasize AI's potential to revolutionize industries while addressing the moral landscape embedded in its execution.\n",
            "\n",
            "1. **Common Themes Across All Research:**\n",
            "\n",
            "   Across the domains of LLMs, AI ethics, and AI enterprise applications, common threads are evident in terms of technological evolution, ethical introspection, and regulatory pursuits. The acceleration in AI's capability and its potential societal impact have spurred intense focus on multimodal proficiencies, responsible AI deployment, and ethical governance frameworks.\n",
            "\n",
            "2. **Key Insights and Patterns:**\n",
            "\n",
            "   - **Enhanced Capabilities:** Technological strides in LLMs and AI systems are reflected in their step-by-step reasoning skills, integration into complex systems like autonomous vehicles, and expanded enterprise applications. Multimodal capabilities are particularly noteworthy, with models like Google's Gemini demonstrating versatility across text, images, and audio.\n",
            "\n",
            "   - **Ethical and Regulatory Frameworks:** There is a growing push towards establishing robust ethical and regulatory landscapes. Initiatives like the EU's AI Act represent a foundational step in global efforts to govern AI responsibly. Ethical considerations such as transparency, accountability, fairness, and privacy are increasingly forming the backbone of AI development.\n",
            "\n",
            "   - **Enterprise Transformation:** Enterprises are leveraging AI to automate processes, enhance decision-making, and improve customer experiences. This transformation is facilitated by AI's ability to offer bespoke solutions and leverage real-time data for strategic insights.\n",
            "\n",
            "3. **Contradictions or Gaps in Findings:**\n",
            "\n",
            "   - **Insufficient Global Regulatory Consensus:** Despite efforts like the EU's AI Act, there remains a lack of global consensus on AI regulation. The gap between technological innovation and regulatory development poses challenges, as ethical principles are often not harmoniously integrated internationally.\n",
            "\n",
            "   - **Balancing Innovation and Ethics:** While strides in AI capabilities are laudable, the tension between pursuing innovation and adhering to ethical standards persists. This dichotomy suggests a need for balanced approaches that nurture technological growth without compromising on ethical tenets.\n",
            "\n",
            "4. **Recommended Follow-Up Research:**\n",
            "\n",
            "   Future research should focus on:\n",
            "   - Evaluating the long-term societal impact of LLM advancements and their integration into everyday technology.\n",
            "   - Expanding international dialogue and collaboration to develop cohesive global regulatory frameworks for AI.\n",
            "   - Exploring how AI-driven decision-making processes can be ethically aligned with societal norms.\n",
            "   - Investigating the potential for AI technologies to bridge industrial gaps and foster equitable access to AI benefits globally.\n",
            "\n",
            "5. **Cohesive Narrative:**\n",
            "\n",
            "   The research in 2024 underscores a pivotal year for AI technology, spotlighting the rapid metamorphosis of LLMs alongside the burgeoning enterprise adoption of AI and the ethical considerations necessitated by such advancements. The transformative potential of AI is clear, as evidenced by its integration into autonomous systems and its capacity to revolutionize enterprise operations through personalized and efficient solutions. Concurrently, the focus on AI ethics and regulation highlights broader societal imperatives, stressing the need for frameworks that both empower innovation and safeguard against ethical lapses. The tapestry woven by these developments manifests a future landscape where AI not only augments human capabilities but also aligns with profound ethical insights, driven by carefully moderated regulatory environments that harness AI's potential responsibly and equitably.\n"
          ]
        }
      ],
      "source": [
        "# Example session\n",
        "assistant = PersistentResearchAssistant(client, th)\n",
        "assistant.start_research_session(\"AI Technology Review\")\n",
        "\n",
        "# Research multiple related topics\n",
        "topics = [\n",
        "    \"Large Language Models in 2024\",\n",
        "    \"AI Ethics and Regulation\",\n",
        "    \"AI in Enterprise Applications\"\n",
        "]\n",
        "\n",
        "for topic in topics:\n",
        "    print(f\"\\n🔍 Researching: {topic}\")\n",
        "    findings = assistant.research_with_context(topic)\n",
        "    print(findings[:300] + \"...\\n\")\n",
        "\n",
        "# Generate session summary\n",
        "print(\"📋 Session Summary:\")\n",
        "summary = assistant.generate_session_summary()\n",
        "print(summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
